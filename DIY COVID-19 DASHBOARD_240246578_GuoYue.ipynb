{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc64ff-4853-42b4-a186-6c1efa70c943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4f65345a54968acf8044e0b5b5bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Refresh data', icon='download', style=ButtonStyle(), tooltip='Click to download current da…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb4b1096f3649e480f5b06937613e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import ipywidgets as wdg\n",
    "\n",
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "\n",
    "########## Click the button to update the data and plot ##########\n",
    "# Creating the output area\n",
    "from ipywidgets import Output, Button\n",
    "out = Output()\n",
    "# Set button function\n",
    "def access_api(button):\n",
    "    with out:\n",
    "        #polling the API here\n",
    "        class APIwrapper:\n",
    "            _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "            _last_access=0.0 # time of last api access\n",
    "            \n",
    "            def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "                \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "                parameters \"\"\"\n",
    "                # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "                # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "                url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                          f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "                # our starting API endpoint\n",
    "                self._start_url=APIwrapper._access_point+url_path\n",
    "                self._filters=None\n",
    "                self._page_size=-1\n",
    "                # will contain the number of items\n",
    "                self.count=None\n",
    "        \n",
    "            def get_page(self, filters={}, page_size=5):\n",
    "                \"\"\" Access the API and download the next page of data. Sets the count\n",
    "                attribute to the total number of items available for this query. Changing\n",
    "                filters or page_size will cause get_page to restart from page 1. Rate\n",
    "                limited to three request per second. The page_size parameter sets the number\n",
    "                of data points in one response page (maximum 365); use the default value \n",
    "                for debugging your structure and filters. \"\"\"\n",
    "                # Check page size is within range\n",
    "                if page_size>365:\n",
    "                    raise ValueError(\"Max supported page size is 365\")\n",
    "                # restart from first page if page or filters have changed\n",
    "                if filters!=self._filters or page_size!=self._page_size:\n",
    "                    self._filters=filters\n",
    "                    self._page_size=page_size\n",
    "                    self._next_url=self._start_url\n",
    "                # signal the end of data condition\n",
    "                if self._next_url==None: \n",
    "                    return [] # we already fetched the last page\n",
    "                # simple rate limiting to avoid bans\n",
    "                curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "                deltat=curr_time-APIwrapper._last_access\n",
    "                if deltat<0.33: # max 3 requests/second\n",
    "                    time.sleep(0.33-deltat)\n",
    "                APIwrapper._last_access=curr_time\n",
    "                # build parameter dictionary by removing all the None\n",
    "                # values from filters and adding page_size\n",
    "                parameters={x: y for x, y in filters.items() if y!=None}\n",
    "                parameters['page_size']=page_size\n",
    "                # the page parameter is already included in _next_url.\n",
    "                # This is the API access. Response is a dictionary with various keys.\n",
    "                # the .json() method decodes the response into Python object (dictionaries,\n",
    "                # lists; 'null' values are translated as None).\n",
    "                response = requests.get(self._next_url, params=parameters).json()\n",
    "                # update url so we'll fetch the next page\n",
    "                self._next_url=response['next']\n",
    "                self.count=response['count']\n",
    "                # data are in the nested 'results' list\n",
    "                return response['results'] \n",
    "        \n",
    "            def get_all_pages(self, filters={}, page_size=365):\n",
    "                \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "                attribute to the total number of items available for this query. API access rate\n",
    "                limited to three request per second. The page_size parameter sets the number\n",
    "                of data points in one response page (maximum 365), and controls the trade-off\n",
    "                between time to load a page and number of pages; the default should work well \n",
    "                in most cases. The number of items returned should in any case be equal to \n",
    "                the count attribute. \"\"\"\n",
    "                data=[] # build up all data here\n",
    "                while True:\n",
    "                    # use get_page to do the job, including the pacing\n",
    "                    next_page=self.get_page(filters, page_size)\n",
    "                    if next_page==[]:\n",
    "                        break # we are done\n",
    "                    data.extend(next_page)\n",
    "                return data\n",
    "        \n",
    "        \n",
    "        structure={\"theme\": \"infectious_disease\", \n",
    "                   \"sub_theme\": \"respiratory\",\n",
    "                   \"topic\": \"COVID-19\",\n",
    "                   \"geography_type\": \"Nation\", \n",
    "                   \"geography\": \"England\", \n",
    "                  }\n",
    "        \n",
    "        #get data of test\n",
    "        structure[\"metric\"]=\"COVID-19_testing_PCRcountByDay\" \n",
    "        api=APIwrapper(**structure)\n",
    "        data_testing=api.get_all_pages()\n",
    "        # print(f\"Data points expected: {api.count}\")\n",
    "        # print(f\"Data points retrieved: {len(data_testing)}\")\n",
    "        # print(data_testing)\n",
    "        with open(\"data_testing.json\", \"wt\") as OUTF:\n",
    "            json.dump(data_testing, OUTF)\n",
    "            \n",
    "        #get data of cases \n",
    "        structure[\"metric\"]=\"COVID-19_cases_casesByDay\" \n",
    "        api=APIwrapper(**structure)\n",
    "        data_cases=api.get_all_pages()\n",
    "        # print(f\"Data points expected: {api.count}\")\n",
    "        # print(f\"Data points retrieved: {len(data_cases)}\")\n",
    "        # print(data_cases)\n",
    "        with open(\"data_cases.json\", \"wt\") as OUTF:\n",
    "            json.dump(data_cases, OUTF)\n",
    "    \n",
    "        # Process data\n",
    "        data={}\n",
    "        for dataset in [data_testing, data_cases]:\n",
    "            for entry in dataset:\n",
    "                date=entry['date']\n",
    "                metric=entry['metric']\n",
    "                value=entry['metric_value']\n",
    "                if date not in data:\n",
    "                    data[date]={}\n",
    "                data[date][metric]=value \n",
    "\n",
    "        dates=list(data.keys())\n",
    "        dates.sort()\n",
    "\n",
    "        \n",
    "        def parse_date(datestring):\n",
    "            \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "            return pd.to_datetime(datestring, format=\"%Y-%m-%d\") \n",
    "        startdate=parse_date(dates[0])\n",
    "        enddate=parse_date(dates[-1])\n",
    "        # print (startdate, ' to ', enddate)\n",
    "        \n",
    "        index=pd.date_range(startdate, enddate, freq='D') #Produces a time index representing the consecutive dates by day (freq='D') from startdate to enddate\n",
    "        timeseriesdf=pd.DataFrame(index=index, columns=['Testing', 'Cases']) #Create a Pandas DataFrame timeseriesdf with the dataframe from pd, the row index is the index (by date of day) generated in the previous step, and the columns are the specified ['testing', 'cases']\n",
    "        \n",
    "        # translate the columns to our metrics\n",
    "        metric ={'Testing': 'COVID-19_testing_PCRcountByDay',\n",
    "                  'Cases': 'COVID-19_cases_casesByDay'}\n",
    "        \n",
    "        for date, entry in data.items():\n",
    "            pd_date=parse_date(date) # convert to Pandas format\n",
    "            for column in ['Testing', 'Cases']: \n",
    "                metric_name=metric[column]\n",
    "                # do not assume all values are there for every date - if a value is not available, insert a 0.0\n",
    "                value= entry.get(metric_name, 0.0)\n",
    "                # this is the way you access a specific location in the dataframe - use .loc\n",
    "                # and put index,column in a single set of [ ]\n",
    "                timeseriesdf.loc[date, column]=value\n",
    "                    \n",
    "        # fill in any remaining \"holes\" due to missing dates\n",
    "        timeseriesdf.fillna(0.0, inplace=True)        \n",
    "        # timeseriesdf\n",
    "        \n",
    "        # # Plotting \n",
    "        # ax=timeseriesdf.plot() # easy peasy... 使用 Pandas 的 .plot() 方法，对数据框 timeseriesdf 中的列进行绘图，默认绘制折线图\n",
    "        # ax.set_title('Daily cases, Daily test-'); #使用 Matplotlib 的 set_title 方法，为绘图设置题。\n",
    "        # ax=timeseriesdf.plot(logy=True) # ...lemon squeezy logy=True将 y 轴设置为对数刻度（logarithmic scale）\n",
    "        # ax.set_title('Daily cases, Daily test(Logarithmic scale)');\n",
    "        \n",
    "        # pandas makes saving to a pickle file dead easy:\n",
    "        timeseriesdf.to_pickle(\"timeseriesdf_cases_test.pkl\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### Multiple-control graphs ###\n",
    "        timeseriesdf=pd.read_pickle(\"timeseriesdf_cases_test.pkl\")#Load the data frame from a pickle file\n",
    "        \n",
    "        # Generate a drop-down list to select data categories\n",
    "        series=wdg.SelectMultiple( \n",
    "            options=list(timeseriesdf.columns), # Dynamically retrieve the column names\n",
    "            value=list(timeseriesdf.columns), # By default, all columns are selected\n",
    "            rows=len(timeseriesdf.columns),\n",
    "            description='Type:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Generate a drop-down list to select the scale\n",
    "        scale=wdg.RadioButtons(\n",
    "            options=['linear', 'log'], # Two options are available: linear and log.\n",
    "            description='Scale:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Extract all years\n",
    "        unique_years = [int(year) for year in timeseriesdf.index.year.unique()] #Ensure that the type of year is int\n",
    "        # Create a year selection control\n",
    "        year_selector = wdg.SelectMultiple(\n",
    "            options=unique_years,  # All years\n",
    "            value= (unique_years[0],),  # The default value is the first year\n",
    "            description='Year:',\n",
    "            rows=5,  \n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Horizontal alignment control\n",
    "        controls=wdg.HBox([year_selector,series, scale]) \n",
    "        \n",
    "        \n",
    "        #Defining plotting functions\n",
    "        def timeseries_graph(gcols, gscale,selected_year):\n",
    "            filtered_df = timeseriesdf[timeseriesdf.index.year.isin(selected_year)] # Filter the data by year\n",
    "            logscale = (gscale == 'log') # Set a logarithmic scale\n",
    "            ncols=len(gcols)\n",
    "            if ncols>0: \n",
    "                filtered_df[list(gcols)].plot(logy=logscale) # Controls whether a logarithmic scale is used\n",
    "                years = ', '.join(map(str, selected_year))  # Concatenate the year as a string\n",
    "                plt.title(f\"Time Series of Selected Types ({years})\")  # Setting the chart title\n",
    "                plt.ylabel(\"Value\")  # Y-axis labels\n",
    "                plt.xlabel(\"Date\")  # X-axis labels\n",
    "                plt.show() # important - graphs won't update if this is missing \n",
    "            else:\n",
    "                print(\"Click to select data for graph\") # Prompt the user to select a data category if no columns are selected\n",
    "                print(\"(CTRL-Click to select more than one category)\") \n",
    "        \n",
    "        # capture output in widget graph   \n",
    "        graph=wdg.interactive_output(timeseries_graph, {'gcols': series, 'gscale': scale,'selected_year':year_selector}) \n",
    "        \n",
    "        display(controls, graph)\n",
    "    \n",
    "        \n",
    "        #Update button state\n",
    "        apibutton.icon=\"check\" # Change the button icon to \"check\" to indicate that the task is complete\n",
    "        apibutton.disabled=True #Prevent repeated clicks\n",
    "\n",
    "# see the doc for the parameters, Creating a button object  \n",
    "apibutton=wdg.Button(\n",
    "    description='Refresh data', \n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to download current data',\n",
    "    icon='download' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "# register the callback function with the button\n",
    "apibutton.on_click(access_api)\n",
    "\n",
    "# display the widgets\n",
    "display(apibutton,out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
